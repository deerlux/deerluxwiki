<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>2.1. scrapy 入门 &mdash; 路路路的学习笔记 0.01.1 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.01.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="路路路的学习笔记 0.01.1 documentation" href="index.html" />
    <link rel="up" title="2. python实用型笔记" href="python.html" />
    <link rel="next" title="3. reStructedText 学习笔记" href="reST.html" />
    <link rel="prev" title="2. python实用型笔记" href="python.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="reST.html" title="3. reStructedText 学习笔记"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="python.html" title="2. python实用型笔记"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">路路路的学习笔记 0.01.1 documentation</a> &raquo;</li>
          <li><a href="python.html" accesskey="U">2. python实用型笔记</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="scrapy">
<h1>2.1. scrapy 入门<a class="headerlink" href="#scrapy" title="Permalink to this headline">¶</a></h1>
<p>因为工作原因要到网络上抓取一些新闻数据来分析，实在不想自己手动解析链接页面，再
重新requests，还要处理多页的问题，一直听说scrapy是个很不错的工具，但一直都没有
花心思学一下，最近几天看了一下，并自己动手编了个程序试了试，确实非常方便。</p>
<p>顺便说一句，网上很多人发的文章都是翻译的官方的Tutorial，官方的Tutorial是挺不错
，但是用到的功能都很基本，抓单个网页分析的话看一下还可以，抓多个网页的功能根本
学不到要，下面以从新浪新闻中抓取文章为例说明，也是我本人学习的一个过程。</p>
<div class="section" id="id1">
<h2>2.1.1. 页面分析<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>比如想要搜关于“国庆放假”的新闻，搜出来的结果如下图所示：</p>
<img alt="_images/sina_search.png" src="_images/sina_search.png" />
<p>我是想把所有搜出来的新闻打开后抓取其标题、新闻来源、发布时间、新闻正文，然后把
相关的内容存储起来准备分析处理，当然不能只抓取搜出来的第一页，而是要把所有的“下
一页”遍历一遍，再抓取。</p>
</div>
<div class="section" id="id2">
<h2>2.1.2. 生成一个scrapy项目<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">startproject</span> <span class="pre">sinanews</span></tt></p>
<p>会生成一个sinanews的目录，然后其中会包含一些必须的文件，网上介绍这些文件干什么
用的文章挺多，就不再重复了，只说实现上述功能我们要修改的文件。</p>
</div>
<div class="section" id="item">
<h2>2.1.3. 定义Item<a class="headerlink" href="#item" title="Permalink to this headline">¶</a></h2>
<p>要存储下来的数据都要存储在Item中，其实它就是一个特殊的dict，在startproject的时
候已经生成了一个基本的模板，你只需要类的定义中加入一些你想要存储的数据结构并把
它们定义为Field()即可。修改items.py文件：</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">SinanewsScrapyItem</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
    <span class="c"># define the fields for your item here like:</span>
    <span class="c"># name = Field()</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">public_time</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="spider">
<h2>2.1.4. 定义Spider<a class="headerlink" href="#spider" title="Permalink to this headline">¶</a></h2>
<p>Spider是抓取的主力军，这个类最为关键，这个类相关的文件并没有自动生成，需要自己
手动新建一个，取名为sinanews_spider.py：</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">#  -*- coding=utf8 -*-</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors</span> <span class="kn">import</span> <span class="n">LinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span>

<span class="kn">from</span> <span class="nn">sinanews_scrapy.items</span> <span class="kn">import</span> <span class="n">SinanewsScrapyItem</span>

<span class="k">class</span> <span class="nc">SinanewsSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;sinanews&#39;</span>
    <span class="n">allowed_domains</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;sina.com.cn&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://search.sina.com.cn/?q=%CF%B0%BD</span><span class="si">%F</span><span class="s">C%C6%BD+%BD%B2%BB%B0&amp;range=title&amp;c=news&amp;sort=time&amp;page=114&#39;</span><span class="p">]</span>

    <span class="n">rules</span> <span class="o">=</span> <span class="p">[</span><span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span> <span class="o">=</span> <span class="s">&#39;/.+/\d+.shtml&#39;</span><span class="p">,</span>
                <span class="n">deny</span> <span class="o">=</span> <span class="s">&#39;/171826152112.shtml&#39;</span><span class="p">),</span>
                <span class="s">&#39;parse_news&#39;</span><span class="p">),</span>
             <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">restrict_xpaths</span> <span class="o">=</span> <span class="s">u&quot;//a[@title=&#39;下一页&#39;]&quot;</span><span class="p">),</span>
                <span class="n">callback</span> <span class="o">=</span> <span class="s">&#39;parse_next&#39;</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">parse_news</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">news</span> <span class="o">=</span> <span class="n">SinanewsScrapyItem</span><span class="p">()</span>

        <span class="n">temp</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&quot;//h1[@id=&#39;artibodyTitle&#39;]//text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">news</span><span class="p">[</span><span class="s">&#39;title&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">temp</span> <span class="k">else</span> <span class="s">&#39;&#39;</span>

        <span class="n">temp</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&quot;//span[@id=&#39;media_name&#39;]//text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">news</span><span class="p">[</span><span class="s">&#39;source&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">temp</span> <span class="k">else</span> <span class="s">&#39;&#39;</span>


        <span class="n">temp</span> <span class="o">=</span>  <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&quot;//span[@id=&#39;pub_date&#39;]//text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">news</span><span class="p">[</span><span class="s">&#39;public_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">temp</span> <span class="k">else</span> <span class="s">&#39;&#39;</span>

        <span class="n">temp</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&quot;//div[@id=&#39;artibody&#39;]//p//text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">news</span><span class="p">[</span><span class="s">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">&#39;</span><span class="se">\n</span><span class="s">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span> <span class="k">if</span> <span class="n">temp</span> <span class="k">else</span> <span class="s">&#39;&#39;</span>

        <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s">&#39;: &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">,</span> <span class="n">news</span><span class="p">[</span><span class="s">&#39;title&#39;</span><span class="p">]]),</span> <span class="n">level</span><span class="o">=</span><span class="n">log</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">news</span>

    <span class="k">def</span> <span class="nf">parse_next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_requests_from_url</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li>类的定义继承自功能更强大的CrawlSpider，而不是Tutorial里讲的Spider。</li>
<li>定义这个Spider的name，这个name作为scrapy crawl XXX的参数在正式进行抓取的时候
会用到。</li>
<li>rule的定义比较关键，这也是CrawlSpider子类的特色，这里定义了一组规则，是作为
跟踪链接的规则，符合规则的网页链接会被跟踪抓取。这里定义了两个规则组成一个
list：一个是跟踪新闻相关的网页，找出这些网页链接网址的规律并用正则表达式定义
allow，那个deny是网页底部有个反淫秽之类的不需要的页面，第三个参数是处理这个页
面的回调函数名称；另一个规则是模拟点击“下一页”然后再进行抓取，找到“下一页”这
个链接用xpath语句定义之，然后跟一个参数follow=True。</li>
<li>这个follow=True让人感觉设计得真是漂亮，开始我在看文档一直想怎么写另外一个回调
函数，然后又怎么递归调用重新启动一次呢，后来在github上找到了geekan抓取douban
的一个例子，原来搞定“下一页”如此简单啊，不得不佩服设计者的用心。很多网上给的
例子都是基本老版本scrapy的（我用0.24.4），还要写一个回调函数单独处理，尽管单
独处理语句也没有几句，但比起这种处理方式来讲还是太麻烦了。第18行往后已经没有
什么技术含量了，无非是找到你想要抓取的东西在html文件中的位置，然后用合适的
xpath表达式把它搜出来，然后逐一赋值给Item类的对应键值，然后将这个对象返回。</li>
</ul>
</div>
<div class="section" id="id3">
<h2>2.1.5. 爬、爬、爬<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p><tt class="docutils literal"><span class="pre">scrapy</span> <span class="pre">crawl</span> <span class="pre">sinanews</span> <span class="pre">-o</span> <span class="pre">sinanews.json</span></tt></p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">2.1. scrapy 入门</a><ul>
<li><a class="reference internal" href="#id1">2.1.1. 页面分析</a></li>
<li><a class="reference internal" href="#id2">2.1.2. 生成一个scrapy项目</a></li>
<li><a class="reference internal" href="#item">2.1.3. 定义Item</a></li>
<li><a class="reference internal" href="#spider">2.1.4. 定义Spider</a></li>
<li><a class="reference internal" href="#id3">2.1.5. 爬、爬、爬</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="python.html"
                        title="previous chapter">2. python实用型笔记</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="reST.html"
                        title="next chapter">3. reStructedText 学习笔记</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/python_scrapy.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="reST.html" title="3. reStructedText 学习笔记"
             >next</a> |</li>
        <li class="right" >
          <a href="python.html" title="2. python实用型笔记"
             >previous</a> |</li>
        <li><a href="index.html">路路路的学习笔记 0.01.1 documentation</a> &raquo;</li>
          <li><a href="python.html" >2. python实用型笔记</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, deerlux.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>